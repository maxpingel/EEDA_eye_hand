{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d2f2c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from IPython.display import display\n",
    "import os\n",
    "import sys\n",
    "from datetime import date,timedelta\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "from math import cos, sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8b98e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkEyeError(files):\n",
    "    df = pd.DataFrame()\n",
    "    for fi in files: # reading all files\n",
    "        with open(fi, 'r') as j:\n",
    "            tmp = json.loads(j.read())\n",
    "            \n",
    "            tempdf0 = pd.DataFrame.from_dict(tmp,orient='index').T        \n",
    "            \n",
    "            tempdf0[[\"EyeValidationError.x\",\"EyeValidationError.y\",\"EyeValidationError.z\"]] = pd.DataFrame(tempdf0[\"EyeValidationError\"].to_list(), columns=['x', 'y','z'])\n",
    "            \n",
    "            if(tempdf0[\"EyeValidationError.x\"][0]<1.5) and (tempdf0[\"EyeValidationError.y\"][0]<1.5):\n",
    "                df = pd.concat([df, tempdf0], ignore_index=True)\n",
    "          \n",
    "\n",
    "    df = df.drop(['IPAddress', 'VRmode',\n",
    "           'SteeringInputDevice', 'EyeValidationError', 'SeatCalibrationOffset',\n",
    "           'TrainingDuration', 'ExperimentDuration', 'ApplicationDuration',\n",
    "           'AverageExperimentFPS', 'SpecialNotes', 'EyeValidationError.z'], axis=1)\n",
    "    return df\n",
    "    #display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f5218ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIncomplete(path,df):\n",
    "    des_index = []\n",
    "    for i in range(0,df['ParticipantUuid'].count()):\n",
    "        name = df['ParticipantUuid'][i]\n",
    "        Liste = SelectAllFilesOfSameName(name,path)\n",
    "        if len(Liste)>4:\n",
    "            des_index.append(i)\n",
    "    df = df.iloc[des_index] \n",
    "    df = df.reset_index(drop=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bae4504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectConditions(df, ConditionName):\n",
    "    df = df[(df.ExperimentalCondition == ConditionName)]#df[(df.ExperimentalCondition == 'Autonomous')] |]\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44a373ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectAllFilesOfSameName(name,path):\n",
    "    files = glob.glob(f'{path}/*.txt')\n",
    "    mylist = list()\n",
    "    for fi in files[:]: # reading all files\n",
    "        if name in fi:\n",
    "            mylist.append(fi)                            \n",
    "    return mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfc284c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectAllCSVOfSameName(path):\n",
    "    files = glob.glob(f'{path}/*.csv')\n",
    "    mylist = list()\n",
    "    for fi in files[:]: # reading all files\n",
    "        mylist.append(fi)                            \n",
    "    return mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ec526f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ToDrop = ['FPS','pupilDiameterMillimetersLeft', 'pupilDiameterMillimetersRight',\n",
    "   'EyeBlinkingWorldLeftTobii', 'EyeBliningWorldRightTobii',\n",
    "   'EyeBlinkingLocalLeftTobii', 'EyeBlinkingLocalRightTobii','hitObjects','HmdRotation_x', 'HmdRotation_y',\n",
    "   'HmdRotation_z', 'HmdRotation_w','EyePositionLeftWorld_x','EyePositionLeftWorld_y', 'EyePositionLeftWorld_z',\n",
    "   'EyeDirectionLeftWorld_x', 'EyeDirectionLeftWorld_y',\n",
    "   'EyeDirectionLeftWorld_z', 'EyePositionLeftLocal_x',\n",
    "   'EyePositionLeftLocal_y', 'EyePositionLeftLocal_z',\n",
    "   'EyeDirectionLeftLocal_x', 'EyeDirectionLeftLocal_y',\n",
    "   'EyeDirectionLeftLocal_z', 'EyePositionRightWorld_x',\n",
    "   'EyePositionRightWorld_y', 'EyePositionRightWorld_z',\n",
    "   'EyePositionRightLocal_x', 'EyePositionRightLocal_y',\n",
    "   'EyePositionRightLocal_z', 'EyeDirectionRightWorld_x',\n",
    "   'EyeDirectionRightWorld_y', 'EyeDirectionRightWorld_z',\n",
    "   'EyeDirectionRightLocal_x', 'EyeDirectionRightLocal_y',\n",
    "   'EyeDirectionRightLocal_z', 'EyePositionWorldCombinedTobii_x',\n",
    "   'EyePositionWorldCombinedTobii_y', 'EyePositionWorldCombinedTobii_z',\n",
    "   'EyePositionLocalCombinedTobii_x', 'EyePositionLocalCombinedTobii_y',\n",
    "   'EyePositionLocalCombinedTobii_z', 'EyeDirectionWorldCombinedTobii_x',\n",
    "   'EyeDirectionWorldCombinedTobii_y', 'EyeDirectionWorldCombinedTobii_z',\n",
    "   'EyeDirectionLocalCombinedTobii_x', 'EyeDirectionLocalCombinedTobii_y',\n",
    "   'EyeDirectionLocalCombinedTobii_z']\n",
    "ToDrop2 = [ 'UnixTimeStamp', 'TobiiTimeStamp',\n",
    "       'EyeOpennessLeftSranipal', 'EyeOpennessRightSranipal', 'HmdPosition_x',\n",
    "       'HmdPosition_y', 'HmdPosition_z', 'NoseVector_x', 'NoseVector_y',\n",
    "       'NoseVector_z', 'EyePositionCombinedWorld_x',\n",
    "       'EyePositionCombinedWorld_y', 'EyePositionCombinedWorld_z', 'EyePositionCombinedLocal_x',\n",
    "       'EyePositionCombinedLocal_y', 'EyePositionCombinedLocal_z',\n",
    "       'CarRotation_x', 'CarRotation_y', 'CarRotation_z',\n",
    "       'CarRotation_w',\n",
    "       'EyeDirectionCombinedLocal_x_copy', 'EyeDirectionCombinedLocal_y_copy',\n",
    "       'EyeDirectionCombinedLocal_z_copy', 'is_blink']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7619022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadEyetrackingData(mylist):\n",
    "    start = time.process_time()\n",
    "    et_df = pd.DataFrame()\n",
    "    #print(\" Before Reading :\",time.process_time() - start)\n",
    "    for fi in mylist:\n",
    "        with open(fi, 'r') as j:\n",
    "            tmp = json.loads(j.read())\n",
    "        for nS, sample in enumerate(tmp):\n",
    "            tmpdf = pd.json_normalize(data=sample, sep='_')\n",
    "            \n",
    "            tmpdf = tmpdf.drop(ToDrop,axis=1)\n",
    "    \n",
    "            et_df = pd.concat([et_df, tmpdf], ignore_index=True)\n",
    "\n",
    "    if not et_df.empty:\n",
    "        et_df = et_df.drop_duplicates()\n",
    "        et_df['uid'] = fi.split('\\\\')[-1].split('_')[0]\n",
    "        et_df['timestamp'] = pd.to_datetime(et_df.UnixTimeStamp, utc=True, unit='s', origin='unix')\n",
    "        et_df = et_df.sort_values(by=['timestamp'])\n",
    "        et_df = et_df.reset_index(drop=True)\n",
    "        et_df.set_index('timestamp', inplace=True)\n",
    "        #print(\" Before Timestamp :\",time.process_time() - start)\n",
    "        et_df['time_from_start'] = (et_df\n",
    "    #                                    .reset_index()\n",
    "    #                                   .groupby(['uid','scene',], as_index=False)\n",
    "    #                                    .timestamp\n",
    "                                   .transform(lambda x: \n",
    "                                              (x.index - x.index[0])/np.timedelta64(1,'s'))\n",
    "                                   .UnixTimeStamp\n",
    "                                   )\n",
    "        et_df = et_df.reset_index()\n",
    "        et_df[['EyeDirectionCombinedLocal_x_copy', 'EyeDirectionCombinedLocal_y_copy', 'EyeDirectionCombinedLocal_z_copy']]=et_df[['EyeDirectionCombinedLocal_x', 'EyeDirectionCombinedLocal_y', 'EyeDirectionCombinedLocal_z']]\n",
    "        et_df['is_blink'] = ((et_df['EyeOpennessLeftSranipal'] < 0.1)&(et_df['EyeOpennessRightSranipal'] < 0.1))\n",
    "        et_df.loc[(et_df['is_blink'] == True),['EyeDirectionCombinedLocal_x_copy', 'EyeDirectionCombinedLocal_y_copy', 'EyeDirectionCombinedLocal_z_copy']] = np.nan\n",
    "\n",
    "        #print(\" Before Interpolation :\",time.process_time() - start)\n",
    "        tmpdf = (et_df\n",
    "                 .groupby(['uid'])['EyeDirectionCombinedLocal_x_copy', 'EyeDirectionCombinedLocal_y_copy', 'EyeDirectionCombinedLocal_z_copy']\n",
    "                 .transform(lambda x: \n",
    "                 x.interpolate(method='polynomial', order=3, limit_direction ='both'))\n",
    "                 .reset_index()\n",
    "                )\n",
    "        et_df[['combinedEyeDir_x_intp', 'combinedEyeDir_y_intp', 'combinedEyeDir_z_intp']] = tmpdf[['EyeDirectionCombinedLocal_x_copy', 'EyeDirectionCombinedLocal_y_copy', 'EyeDirectionCombinedLocal_z_copy']]\n",
    "        #et_df = et_df.drop(ToDrop2,axis=1)  \n",
    "        #print(\" After Interpolation :\",time.process_time() - start)\n",
    "        return et_df\n",
    "        #return et_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b8a00dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadSteeringData(mylist):\n",
    "    start = time.process_time()\n",
    "    et_df = pd.DataFrame()\n",
    "    for fi in mylist:\n",
    "        with open(fi, 'r') as j:\n",
    "            tmp = json.loads(j.read())\n",
    "        for nS, sample in enumerate(tmp):\n",
    "            tmpdf = pd.json_normalize(data=sample, sep='_')\n",
    "            et_df = pd.concat([et_df, tmpdf], ignore_index=True)\n",
    "            \n",
    "    \n",
    "    if not et_df.empty:\n",
    "        et_df = et_df.drop_duplicates()\n",
    "        et_df['uid'] = fi.split('\\\\')[-1].split('_')[0]\n",
    "        et_df['timestamp'] = pd.to_datetime(et_df.TimeStamp, utc=True, unit='s', origin='unix')\n",
    "        et_df = et_df.sort_values(by=['timestamp'])\n",
    "        et_df = et_df.reset_index(drop=True)\n",
    "        et_df = et_df.reset_index(drop=True)\n",
    "        \n",
    "        #print(\" Steering Reading :\",time.process_time() - start)\n",
    "        return et_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f46c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CombineSteeringAndET(et_df,st_df):\n",
    "    \n",
    "    \n",
    "    st_df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    #Check if DF are equally long\n",
    "    b = st_df.shape[0]- et_df.shape[0]\n",
    "    st_df.drop(st_df.tail(b).index,inplace=True)\n",
    "\n",
    "    st_df = st_df.reset_index()\n",
    "    \n",
    "    et_df['Equal'] = np.where(et_df['timestamp'] == st_df['timestamp'],True,False)\n",
    "    et_df[['SteeringInput', 'AcellerationInput', 'BrakeInput']] = st_df[['SteeringInput', 'AcellerationInput', 'BrakeInput']]\n",
    "    return et_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "871772b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadEventData(mylist):\n",
    "    interims_df = pd.DataFrame()\n",
    "    Event_dur_df = pd.DataFrame()\n",
    "    Event_object_movement_df = pd.DataFrame()\n",
    "    event_samples_df = pd.DataFrame()\n",
    "    for fi in mylist:\n",
    "        with open(fi, 'r') as j:\n",
    "            tmp = json.loads(j.read())\n",
    "            x = tmp.get('EventBehavior')\n",
    "            for p in range(len(x)):\n",
    "                tmpdf = pd.json_normalize(data=x[p], sep='_')\n",
    "                interims_df = tmpdf[['EventName', 'StartofEventTimeStamp', 'EndOfEventTimeStamp',\n",
    "           'EventDuration', 'SuccessfulCompletionState', 'HitObjectName']]\n",
    "                Event_dur_df = pd.concat([Event_dur_df,interims_df],ignore_index = True)\n",
    "                tmpdf2 = pd.json_normalize(tmpdf[\"dynamicObjectData\"])\n",
    "                for nS, sample in enumerate(tmpdf2):\n",
    "                    temp = list(tmpdf2[nS])\n",
    "                    tmpdf3 = pd.json_normalize(data=temp, sep='_')\n",
    "                    tmpdf3['uid'] = fi.split('\\\\')[-1].split('_')[0]\n",
    "                    tmpdf3['scene'] = fi.split('_')[-1].split('.')[0]\n",
    "                    tmpdf3[['EventName', 'StartofEventTimeStamp', 'EndOfEventTimeStamp',\n",
    "           'EventDuration', 'SuccessfulCompletionState', 'HitObjectName']] = interims_df[['EventName', 'StartofEventTimeStamp', 'EndOfEventTimeStamp',\n",
    "           'EventDuration', 'SuccessfulCompletionState', 'HitObjectName']]\n",
    "                    event_samples_df = pd.concat([event_samples_df, tmpdf3], ignore_index=True)\n",
    "    if not event_samples_df.empty:\n",
    "        event_samples_df = event_samples_df.drop_duplicates()\n",
    "        \n",
    "        event_samples_df['timestamp'] = pd.to_datetime(event_samples_df.UnixTimeStamp, utc=True, unit='s', origin='unix')\n",
    "        event_samples_df['StartofEventTime'] = pd.to_datetime(event_samples_df.StartofEventTimeStamp, utc=True, unit='s', origin='unix')\n",
    "        event_samples_df['EndofEventTime'] = pd.to_datetime(event_samples_df.EndOfEventTimeStamp, utc=True, unit='s', origin='unix')\n",
    "        event_samples_df = event_samples_df.sort_values(by=['timestamp'])\n",
    "        \n",
    "        Event_object_movement_df = event_samples_df[['uid','EventName','timestamp','ObjectName0', 'ObjectName1', 'ObjectName2',\n",
    "       'ObjectPosition0.x', 'ObjectPosition0.y', 'ObjectPosition0.z','ObjectPosition1.x', 'ObjectPosition1.y',\n",
    "       'ObjectPosition1.z','ObjectPosition2.x', 'ObjectPosition2.y', 'ObjectPosition2.z']]\n",
    "        \n",
    "        event_samples_df = event_samples_df.drop(['UnixTimeStamp', 'ObjectName0', 'ObjectName1', 'ObjectName2',\n",
    "       'ObjectPosition0.x', 'ObjectPosition0.y', 'ObjectPosition0.z','timestamp',\n",
    "       'ObjectRotation0.x', 'ObjectRotation0.y', 'ObjectRotation0.z',\n",
    "       'ObjectRotation0.w', 'ObjectPosition1.x', 'ObjectPosition1.y',\n",
    "       'ObjectPosition1.z', 'ObjectRotation1.x', 'ObjectRotation1.y',\n",
    "       'ObjectRotation1.z', 'ObjectRotation1.w', 'ObjectPosition2.x',\n",
    "       'ObjectPosition2.y', 'ObjectPosition2.z', 'ObjectRotation2.x',\n",
    "       'ObjectRotation2.y', 'ObjectRotation2.z', 'ObjectRotation2.w',  'StartofEventTimeStamp', 'EndOfEventTimeStamp',\n",
    "        'HitObjectName'\n",
    "       ],axis=1)\n",
    "        \n",
    "        \n",
    "        #event_samples_df.to_csv(path)\n",
    "        #event_samples_df = event_samples_df[(event_samples_df.EventName == 'Event_2')|(event_samples_df.EventName == 'Event_6')|(event_samples_df.EventName == 'Event_8')|(event_samples_df.EventName == 'Event_10')]\n",
    "        Event_object_movement_df = Event_object_movement_df.drop_duplicates().reset_index(drop=True)\n",
    "        event_samples_df = event_samples_df.drop_duplicates().reset_index(drop=True)\n",
    "        #Event_object_movement_df.to_csv(path2)\n",
    "        return(event_samples_df,Event_object_movement_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8055d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EyeThetaCalculation(et_samples_df):\n",
    "    et_samples_df.reset_index(inplace=False)\n",
    "    et_samples_df['eye_theta_h'] = np.arctan2(et_samples_df['EyeDirectionCombinedLocal_x'], \n",
    "                                           et_samples_df['EyeDirectionCombinedLocal_z'])\n",
    "    et_samples_df['eye_theta_v'] = np.arctan2(et_samples_df['EyeDirectionCombinedLocal_y'], \n",
    "                                           et_samples_df['EyeDirectionCombinedLocal_z'])\n",
    "    et_samples_df['eye_theta_h_int'] = np.arctan2(et_samples_df['combinedEyeDir_x_intp'], \n",
    "                                           et_samples_df['combinedEyeDir_z_intp'])\n",
    "    et_samples_df['eye_theta_v_int'] = np.arctan2(et_samples_df['combinedEyeDir_y_intp'], \n",
    "                                           et_samples_df['combinedEyeDir_z_intp'])\n",
    "    return et_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96a929e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EyeThetaCalculationWorld(et_samples_df):\n",
    "    et_samples_df.reset_index(inplace=False)\n",
    "    et_samples_df['eye_theta_h_World'] = np.arctan2(et_samples_df['EyeDirectionCombinedWorld_x'], \n",
    "                                           et_samples_df['EyeDirectionCombinedWorld_z'])\n",
    "   \n",
    "    return et_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a71d6ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateEventTime(et_df,et_dur_df):\n",
    "    Start = et_df.iloc[0]['timestamp']\n",
    "    for t in range(0,et_dur_df['uid'].count()):\n",
    "        et_dur_df['StartofEventTime'][t]=(pd.to_datetime(et_dur_df['StartofEventTime'][t])-pd.to_datetime(Start)).total_seconds()\n",
    "        et_dur_df['EndofEventTime'][t]=(pd.to_datetime(et_dur_df['EndofEventTime'][t])-pd.to_datetime(Start)).total_seconds()\n",
    "\n",
    "    #display(et_dur_df)\n",
    "    return et_dur_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0946417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CutDatatoEvents(df,evt_df,mylist,EVTpath,mvmt_df):\n",
    "    for index, row in evt_df.iterrows():\n",
    "        #print(df)\n",
    "        #print(evt_df)\n",
    "        if row['SuccessfulCompletionState']:\n",
    "            Event_O_df = pd.DataFrame()\n",
    "            EventStart = row['StartofEventTime'] -1\n",
    "            EventMvmStart = row['StartofEventTime']\n",
    "            EventEnd = row['EndofEventTime'] + 1 \n",
    "            EventMvmEnd = row['EndofEventTime']\n",
    "            Start_index = df['time_from_start'].sub(EventStart).abs().idxmin()\n",
    "            End_index = df['time_from_start'].sub(EventEnd).abs().idxmin()\n",
    "            Start_index_mvm = df['time_from_start'].sub(EventMvmStart).abs().idxmin()\n",
    "            End_index_mvm = df['time_from_start'].sub(EventMvmEnd).abs().idxmin()\n",
    "            EventName = row['EventName']\n",
    "\n",
    "            path = os.path.join(EVTpath,EventName+'.csv')\n",
    "\n",
    "            if \"..\\\\Only_Events\\\\\"+EventName+\".csv\" in mylist[:]:\n",
    "                Event_O_df = pd.read_csv(path)\n",
    "                print(\"Found file \", EventName)\n",
    "            else :\n",
    "                Event_O_df = pd.DataFrame()\n",
    "                print(\"New File\")\n",
    "            new_df1 = df.loc[Start_index:Start_index_mvm]\n",
    "            \n",
    "            new_df1.loc[:, \"EventTime\"] = new_df1[\"time_from_start\"].apply(lambda x: x - (EventStart+1))\n",
    "            \n",
    "            new_df2 = df.loc[Start_index_mvm:End_index_mvm]\n",
    "            \n",
    "            new_df2.loc[:, \"EventTime\"] = new_df2[\"time_from_start\"].apply(lambda x: x - (EventStart+1))\n",
    "            #print(\"df2\" , new_df2.shape)\n",
    "            evt_df2 = mvmt_df.loc[mvmt_df['EventName'] == EventName]\n",
    "            new_df2 = pd.merge(new_df2,evt_df2,how = 'left',on = 'timestamp',suffixes = ['','_'])\n",
    "            \n",
    "            #print(\"mvm\",evt_df2.shape )\n",
    "            #print(\"newNewdf2\", new_df2.shape)\n",
    "            new_df3 = df.loc[End_index_mvm:End_index]\n",
    "            \n",
    "            new_df3.loc[:, \"EventTime\"] = new_df3[\"time_from_start\"].apply(lambda x: x - (EventStart+1))\n",
    "            \n",
    "            new_df = pd.concat([new_df1,new_df2,new_df3], ignore_index=True)\n",
    "            Event_O_df = pd.concat([Event_O_df, new_df], ignore_index=True)\n",
    "            \n",
    "\n",
    "            Event_O_df.to_csv(path, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26c6da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAverage(df,stringD,binS):\n",
    "    \n",
    "    df = df.sort_values(by = stringD)\n",
    "    \n",
    "    df['bins'] = pd.cut(\n",
    "        df[stringD], \n",
    "        bins=np.arange(df[stringD].iloc[0],df[stringD].iloc[-1]+binS,binS),\n",
    "        labels=np.arange(df[stringD].iloc[0]+binS,df[stringD].iloc[-1]+binS,binS)\n",
    "        )\n",
    "    df['bins'] = df['bins'].astype(float)\n",
    "    df4 = df.groupby('bins').agg({\n",
    "        #'RoadAngle':np.nanmean,\n",
    "        'SteeringInput':np.nanmean,\n",
    "        'AcellerationInput':np.nanmean,\n",
    "        'BrakeInput':np.nanmean,\n",
    "        'time_from_start':np.nanmean,\n",
    "        'CarPosition_x':np.nanmean,\n",
    "        'CarPosition_z':np.nanmean,\n",
    "        'eye_theta_h':np.nanmean,\n",
    "        'eye_theta_h_HEAD':np.nanmean,\n",
    "        'eye_theta_h_World':np.nanmean,\n",
    "        'AutoRotation_R_Y':np.nanmean,\n",
    "        'Head_theta_h':np.nanmean,\n",
    "        'nose_theta_h':np.nanmean\n",
    "        }).reset_index()\n",
    "    return df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3ac37c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckForSteeringNulls(df):\n",
    "    uids = list(df.uid.unique())\n",
    "    for u in uids:\n",
    "        df2 = df.loc[df['uid'] == u]\n",
    "        df.loc[df['uid'] == u, ['SteeringInput_']] = ((df2['SteeringInput']-df2['SteeringInput'].mean())/df2['SteeringInput'].std())\n",
    "        unique = list(df2.SteeringInput.unique())\n",
    "        if(len(unique)<2):\n",
    "            df.loc[df['uid'] == u, ['SteeringInput']] = np.nan\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a4e57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Distance(df):\n",
    "    #classes = list(df.uid.unique())\n",
    "    #for c in classes[:]:\n",
    "    #print(df.shape)\n",
    "    point2 = np.array((df['CarPosition_x'].values[0], df['CarPosition_y'].values[0], df['CarPosition_z'].values[0]))\n",
    "\n",
    "    distance = list()\n",
    "\n",
    "\n",
    "    summi = 0\n",
    "    #print(\"df.shape\")\n",
    "    for index, row in df.iterrows():\n",
    "        point1 = np.array((row['CarPosition_x'], row['CarPosition_y'], row['CarPosition_z']))\n",
    "        temp = point1 - point2\n",
    "        sum_sq = np.dot(temp.T, temp)\n",
    "        distance.append( np.sqrt(sum_sq)+summi)\n",
    "        summi =  np.sqrt(sum_sq)+summi\n",
    "        point2 = point1\n",
    "    #print(sum(distance))\n",
    "    #print(distance)\n",
    "    df['Distance'] = np.array(distance)\n",
    "    #print(len(distance))\n",
    "\n",
    "    #df2['Distance']= np.array(distance)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27b29bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RotationStuff(df_A):   \n",
    "\n",
    "    df_B = pd.DataFrame()\n",
    "    # We want the head rotation horizontal\n",
    "    # we have the eyedirection_world, car rotation and eye direction local\n",
    "    # headrotation should be the eyedirection world minus car rotation and minus eye local\n",
    "    # car rotation is in quaternion\n",
    "    # eyedirection world is euler so is eyelocal\n",
    "\n",
    "    #Car rotation to Rotation Matrix\n",
    "    df_B['CarRotation_all'] = df_A[[\n",
    "    'CarRotation_x', 'CarRotation_y', 'CarRotation_z', 'CarRotation_w'\n",
    "    ]].apply(lambda r: tuple(r), axis=1).apply(np.array)\n",
    "    df_B['AutoRotation_R'] = df_B['CarRotation_all'].apply(R)\n",
    "    df_B['AutoRotation_R_euler'] = df_B['AutoRotation_R'].apply(Euler)\n",
    "    #df_B['AutoRotation_R_euler_Z'] = df_B['AutoRotation_R_euler'].apply(lambda x: x[0])\n",
    "    #df_B['AutoRotation_R_euler_Y'] = df_B['AutoRotation_R_euler'].apply(lambda x: x[1])\n",
    "    #df_B['AutoRotation_R_euler_X'] = df_B['AutoRotation_R_euler'].apply(lambda x: x[2])\n",
    "\n",
    "    df_B['EyeDirectionCombinedWorld'] = df_A[['EyeDirectionCombinedWorld_z', 'EyeDirectionCombinedWorld_y',\n",
    "       'EyeDirectionCombinedWorld_x'\n",
    "    ]].apply(lambda r: tuple(r), axis=1).apply(np.array)\n",
    "    df_B['Combined_Nose'] = df_A[['NoseVector_z', 'NoseVector_y',\n",
    "       'NoseVector_x'\n",
    "    ]].apply(lambda r: tuple(r), axis=1).apply(np.array)\n",
    "    df_B['AutoRotation_R_inv'] = (df_B['AutoRotation_R'].apply(lambda x: x.inv()))\n",
    "    df_B['New_Nose'] = df_B['AutoRotation_R_inv']\n",
    "    df_B['New_Direction_2'] = df_B['AutoRotation_R']\n",
    "    for index, row in df_B.iterrows():\n",
    "        #row['New_Direction']= (row['AutoRotation_R_inv'].apply(row['EyeDirectionCombinedWorld']))\n",
    "        row['New_Direction_2']= (row['AutoRotation_R'].apply(row['EyeDirectionCombinedWorld']))\n",
    "        row['New_Nose']=(row['AutoRotation_R'].apply(row['Combined_Nose']))\n",
    "\n",
    "    df_B['HeadRotation_R_euler_Z'] = df_B['New_Direction_2'].apply(lambda x: x[0])\n",
    "    df_B['HeadRotation_R_euler_Y'] = df_B['New_Direction_2'].apply(lambda x: x[1])\n",
    "    df_B['HeadRotation_R_euler_X'] = df_B['New_Direction_2'].apply(lambda x: x[2])\n",
    "    df_B['Nose_euler_Z'] = df_B['New_Nose'].apply(lambda x: x[0])\n",
    "    df_B['Nose_euler_Y'] = df_B['New_Nose'].apply(lambda x: x[1])\n",
    "    df_B['Nose_euler_X'] = df_B['New_Nose'].apply(lambda x: x[2])\n",
    "\n",
    "    df_B.reset_index(inplace=False)\n",
    "    df_A['eye_theta_h_HEAD'] = np.arctan2(df_B['HeadRotation_R_euler_X'], \n",
    "                                           df_B['HeadRotation_R_euler_Z'])\n",
    "    df_A['eye_theta_h_World'] = np.arctan2(df_A['EyeDirectionCombinedWorld_x'], \n",
    "                                           df_A['EyeDirectionCombinedWorld_z'])\n",
    "    \n",
    "    df_A['nose_theta_h'] = np.arctan2(df_B['Nose_euler_X'], \n",
    "                                           df_B['Nose_euler_Z'])\n",
    "    df_A['AutoRotation_R_Y'] = df_B['AutoRotation_R_euler'].apply(lambda x: x[1])\n",
    "    df_A['Head_theta_h'] = df_A['eye_theta_h_HEAD'] - df_A['eye_theta_h'] \n",
    "    df_A = ThetaWorldToNan(df_A,'Head_theta_h') \n",
    "    df_A = ThetaWorldToNan(df_A,'eye_theta_h_HEAD') \n",
    "    df_A = ThetaWorldToNan(df_A,'eye_theta_h') \n",
    "    df_A = ThetaWorldToNan(df_A,'eye_theta_h_World')\n",
    "    \n",
    "    \"\"\"\n",
    "    #Eyedirection_world to TM\n",
    "\n",
    "    df_B['EyeDirectionCombinedWorld_R'] = df_B['EyeDirectionCombinedWorld'].apply(From_Euler)\n",
    "\n",
    "    #Eyedirection_Local to TM\n",
    "\n",
    "    df_B['EyeDirectionCombinedLocal'] = df_A[['EyeDirectionCombinedLocal_z', 'EyeDirectionCombinedLocal_y',\n",
    "       'EyeDirectionCombinedLocal_x'\n",
    "    ]].apply(lambda r: tuple(r), axis=1).apply(np.array)\n",
    "    df_B['EyeDirectionCombinedLocal_R'] = df_B['EyeDirectionCombinedLocal'].apply(From_Euler)\n",
    "\n",
    "    df_B['PureHead'] = df_B['EyeDirectionCombinedWorld_R']*(df_B['AutoRotation_R'].apply(lambda x: x.inv()))*(df_B['EyeDirectionCombinedLocal_R'].apply(lambda x: x.inv()))\n",
    "\n",
    "\n",
    "    #Car rotation to Euler\n",
    "    df_B['HeadRotation_R_euler'] = df_B['PureHead'].apply(Euler)\n",
    "\n",
    "    ### spliting zyx values\n",
    "    df_B['HeadRotation_R_euler_Z'] = df_B['HeadRotation_R_euler'].apply(lambda x: x[0])\n",
    "    df_B['HeadRotation_R_euler_Y'] = df_B['HeadRotation_R_euler'].apply(lambda x: x[1])\n",
    "    df_B['HeadRotation_R_euler_X'] = df_B['HeadRotation_R_euler'].apply(lambda x: x[2])\n",
    "\n",
    "    df_B.reset_index(inplace=False)\n",
    "    df_A['eye_theta_h_HEAD'] = np.arctan2(df_B['HeadRotation_R_euler_X'], \n",
    "                                           df_B['HeadRotation_R_euler_Z'])\n",
    "\n",
    "    df_A['eye_theta_h_Car'] = np.arctan2(df_B['AutoRotation_R_euler_X'], \n",
    "                                           df_B['AutoRotation_R_euler_Z'])\n",
    "    df_B['time_from_start'] = df_A['time_from_start']\"\"\"\n",
    "    #print(df_A.columns)\n",
    "    #display(df_A)\n",
    "    return df_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ce636a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for converting t o Euler angles\n",
    "\n",
    "def Euler(x):\n",
    "    from scipy.spatial.transform import Rotation as R\n",
    "    Euler_angles = x.as_euler('zyx', degrees=True)\n",
    "    return Euler_angles\n",
    "\n",
    "\n",
    "def From_Euler(x):\n",
    "    from scipy.spatial.transform import Rotation as R\n",
    "    R = R.from_euler('zyx', x, degrees=True)\n",
    "    return R\n",
    "\n",
    "\n",
    "def R(x):\n",
    "    from scipy.spatial.transform import Rotation as R\n",
    "    R = R.from_quat(x)\n",
    "    return R\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
