{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d753d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib widget\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from IPython.display import display\n",
    "import os\n",
    "import sys\n",
    "from datetime import date\n",
    "import json\n",
    "import numpy as np\n",
    "#print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5097169",
   "metadata": {},
   "outputs": [],
   "source": [
    "ET_DATA_PATH = r'C:\\Users\\Max\\MasterMax\\EyeTracking'\n",
    "SCENE_EVENT_DATA_PATH = r'C:\\Users\\Max\\MasterMax\\SceneData'\n",
    "STEERING_DATA_PATH = r'C:\\Users\\Max\\MasterMax\\Input'\n",
    "PARTICIPANT_DATA_PATH = r'C:\\Users\\Max\\MasterMax\\ParticipantCalibrationData'\n",
    "PROCESSED_DATA_PATH = '..\\csv_et'\n",
    "COMBINED_DATA_PATH = '..\\et_comb'\n",
    "EVENT_DURATION_DATA_PATH = '..\\Event_dur'\n",
    "ONLY_EVENTS_DATA_PATH = '..\\Only_Events'\n",
    "\n",
    "PLOT_PATH = '..\\PLOTS\\data_quality'\n",
    "os.makedirs(os.path.dirname(PROCESSED_DATA_PATH),exist_ok=True)\n",
    "os.makedirs(os.path.dirname(COMBINED_DATA_PATH),exist_ok=True)\n",
    "os.makedirs(os.path.dirname(PLOT_PATH), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0359c514",
   "metadata": {},
   "source": [
    "### Filter EyeValidationError under 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095aa32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#files = glob.glob(f'{PARTICIPANT_DATA_PATH}/*.txt')\n",
    "def checkEyeError(files):\n",
    "    df = pd.DataFrame()\n",
    "    for fi in files[:]: # reading all files\n",
    "        with open(fi, 'r') as j:\n",
    "            tmp = json.loads(j.read())\n",
    "            tempdf0 = pd.DataFrame.from_dict(tmp,orient='index').T        \n",
    "            tempdf0[[\"EyeValidationError.x\",\"EyeValidationError.y\",\"EyeValidationError.z\"]] = pd.DataFrame(tempdf0[\"EyeValidationError\"].to_list(), columns=['x', 'y','z'])\n",
    "            if(tempdf0[\"EyeValidationError.x\"][0]<1.5) and (tempdf0[\"EyeValidationError.y\"][0]<1.5):\n",
    "                df = pd.concat([df, tempdf0], ignore_index=True)\n",
    "\n",
    "    df = df.drop(['IPAddress', 'VRmode',\n",
    "           'SteeringInputDevice', 'EyeValidationError', 'SeatCalibrationOffset',\n",
    "           'TrainingDuration', 'ExperimentDuration', 'ApplicationDuration',\n",
    "           'AverageExperimentFPS', 'SpecialNotes', 'EyeValidationError.z'], axis=1)\n",
    "    return df\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c79a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Participant_files = glob.glob(f'{PARTICIPANT_DATA_PATH}/*.txt')\n",
    "ET_files = glob.glob(f'{ET_DATA_PATH}/*.txt')\n",
    "df = pd.DataFrame()\n",
    "df = checkEyeError(Participant_files)\n",
    "#display(df)\n",
    "df = checkIncomplete(ET_files,df)\n",
    "#display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a92c93",
   "metadata": {},
   "source": [
    "### Check if Incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de890054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#files = glob.glob(f'{ET_DATA_PATH}/*.txt')\n",
    "def checkIncomplete(Incompl_files,df):\n",
    "    des_index = []\n",
    "    for i in range(0,df['ParticipantUuid'].count()):\n",
    "        for fi in Incompl_files[:]: # reading all files\n",
    "            #print (df['ParticipantUuid'][i])\n",
    "            if '_Incomplete' in fi:\n",
    "                if df['ParticipantUuid'][i] in fi:\n",
    "                    if os.path.getsize(fi) < 10 : \n",
    "                        des_index.append(i)\n",
    "\n",
    "\n",
    "    df = df.iloc[des_index] \n",
    "    df = df.reset_index(drop=True)\n",
    "    return(df)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c06f7f",
   "metadata": {},
   "source": [
    "### Load Eyetracking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b96cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f'{ET_DATA_PATH}/*.txt')\n",
    "for i in range(0,df['ParticipantUuid'].count()):\n",
    "    et_df = pd.DataFrame()\n",
    "    for fi in files[:]: # reading all files\n",
    "        if df['ParticipantUuid'][i] in fi:\n",
    "            with open(fi, 'r') as j:\n",
    "                tmp = json.loads(j.read())\n",
    "            for nS, sample in enumerate(tmp):\n",
    "                tmpdf = pd.json_normalize(data=sample, sep='_')\n",
    "                tmpdf['uid'] = fi.split('\\\\')[-1].split('_')[0]\n",
    "                tmpdf['scene'] = fi.split('_')[-1].split('.')[0]\n",
    "                tmpdf = tmpdf.drop(['FPS','pupilDiameterMillimetersLeft', 'pupilDiameterMillimetersRight',\n",
    "       'EyeBlinkingWorldLeftTobii', 'EyeBliningWorldRightTobii',\n",
    "       'EyeBlinkingLocalLeftTobii', 'EyeBlinkingLocalRightTobii', 'hitObjects',\n",
    "       'HmdRotation_x', 'HmdRotation_y',\n",
    "       'HmdRotation_z', 'HmdRotation_w','EyePositionLeftWorld_x',\n",
    "       'EyePositionLeftWorld_y', 'EyePositionLeftWorld_z',\n",
    "       'EyeDirectionLeftWorld_x', 'EyeDirectionLeftWorld_y',\n",
    "       'EyeDirectionLeftWorld_z', 'EyePositionLeftLocal_x',\n",
    "       'EyePositionLeftLocal_y', 'EyePositionLeftLocal_z',\n",
    "       'EyeDirectionLeftLocal_x', 'EyeDirectionLeftLocal_y',\n",
    "       'EyeDirectionLeftLocal_z', 'EyePositionRightWorld_x',\n",
    "       'EyePositionRightWorld_y', 'EyePositionRightWorld_z',\n",
    "       'EyePositionRightLocal_x', 'EyePositionRightLocal_y',\n",
    "       'EyePositionRightLocal_z', 'EyeDirectionRightWorld_x',\n",
    "       'EyeDirectionRightWorld_y', 'EyeDirectionRightWorld_z',\n",
    "       'EyeDirectionRightLocal_x', 'EyeDirectionRightLocal_y',\n",
    "       'EyeDirectionRightLocal_z', 'EyePositionWorldCombinedTobii_x',\n",
    "       'EyePositionWorldCombinedTobii_y', 'EyePositionWorldCombinedTobii_z',\n",
    "       'EyePositionLocalCombinedTobii_x', 'EyePositionLocalCombinedTobii_y',\n",
    "       'EyePositionLocalCombinedTobii_z', 'EyeDirectionWorldCombinedTobii_x',\n",
    "       'EyeDirectionWorldCombinedTobii_y', 'EyeDirectionWorldCombinedTobii_z',\n",
    "       'EyeDirectionLocalCombinedTobii_x', 'EyeDirectionLocalCombinedTobii_y',\n",
    "       'EyeDirectionLocalCombinedTobii_z'],axis=1)\n",
    "                \n",
    "                et_df = pd.concat([et_df, tmpdf], ignore_index=True)\n",
    "                   \n",
    "    if not et_df.empty:\n",
    "        et_df = et_df.drop_duplicates()\n",
    "        et_df['timestamp'] = pd.to_datetime(et_df.UnixTimeStamp, utc=True, unit='s', origin='unix')\n",
    "        et_df = et_df.sort_values(by=['timestamp'])\n",
    "        et_df = et_df.reset_index(drop=True)\n",
    "        path = os.path.join(PROCESSED_DATA_PATH,df['ParticipantUuid'][i]+'.csv')\n",
    "        print(100/df['ParticipantUuid'].count()*(i+1),\"%\")\n",
    "        et_df.set_index('timestamp', inplace=True)\n",
    "        et_df['time_from_start'] = (et_df\n",
    "#                                    .reset_index()\n",
    "#                                   .groupby(['uid','scene',], as_index=False)\n",
    "#                                    .timestamp\n",
    "                                   .transform(lambda x: \n",
    "                                              (x.index - x.index[0])/np.timedelta64(1,'s'))\n",
    "                                   .UnixTimeStamp\n",
    "                                   )\n",
    "        et_df = et_df.reset_index()\n",
    "        et_df[['EyeDirectionCombinedLocal_x_copy', 'EyeDirectionCombinedLocal_y_copy', 'EyeDirectionCombinedLocal_z_copy']]=et_df[['EyeDirectionCombinedLocal_x', 'EyeDirectionCombinedLocal_y', 'EyeDirectionCombinedLocal_z']]\n",
    "        et_df['is_blink'] = ((et_df['EyeOpennessLeftSranipal'] < 0.1)&(et_df['EyeOpennessRightSranipal'] < 0.1))\n",
    "        et_df.loc[(et_df['is_blink'] == True),['EyeDirectionCombinedLocal_x_copy', 'EyeDirectionCombinedLocal_y_copy', 'EyeDirectionCombinedLocal_z_copy']] = np.nan\n",
    "        \n",
    "        tmpdf = (et_df\n",
    "                 .groupby(['uid', 'scene'])['EyeDirectionCombinedLocal_x_copy', 'EyeDirectionCombinedLocal_y_copy', 'EyeDirectionCombinedLocal_z_copy']\n",
    "                 .transform(lambda x: \n",
    "                 x.interpolate(method='polynomial', order=3, limit_direction ='both'))\n",
    "                 .reset_index()\n",
    "                )\n",
    "        et_df[['combinedEyeDir_x_intp', 'combinedEyeDir_y_intp', 'combinedEyeDir_z_intp']] = tmpdf[['EyeDirectionCombinedLocal_x_copy', 'EyeDirectionCombinedLocal_y_copy', 'EyeDirectionCombinedLocal_z_copy']]\n",
    "\n",
    "\n",
    "        path = os.path.join(PROCESSED_DATA_PATH,df['ParticipantUuid'][i]+'.csv')\n",
    "        print(100/df['ParticipantUuid'].count()*(i+1),\"%\")\n",
    "        et_df.to_csv(path)\n",
    "        #display(et_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c277d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_df.query(\"TobiiTimeStamp==0\").EyeDirectionCombinedLocal_y.EyeDirectionCombinedLocal_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf29896",
   "metadata": {},
   "source": [
    "### Steeringwheel Data read and write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e3639",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f'{STEERING_DATA_PATH}/*.txt')\n",
    "for i in range(0,df['ParticipantUuid'].count()):\n",
    "    et_df = pd.DataFrame()\n",
    "    for fi in files[:]: # reading all files\n",
    "        if df['ParticipantUuid'][i] in fi:\n",
    "            #print(\"file found \")\n",
    "            with open(fi, 'r') as j:\n",
    "                tmp = json.loads(j.read())\n",
    "            for nS, sample in enumerate(tmp):\n",
    "                tmpdf = pd.json_normalize(data=sample, sep='_')\n",
    "                tmpdf['uid'] = fi.split('\\\\')[-1].split('_')[0]\n",
    "                tmpdf['scene'] = fi.split('_')[-1].split('.')[0]\n",
    "                et_df = pd.concat([et_df, tmpdf], ignore_index=True)\n",
    "                #print(sample)\n",
    "    \n",
    "    if not et_df.empty:\n",
    "        et_df = et_df.drop_duplicates()\n",
    "        et_df['timestamp'] = pd.to_datetime(et_df.TimeStamp, utc=True, unit='s', origin='unix')\n",
    "        et_df = et_df.sort_values(by=['timestamp'])\n",
    "        #et_df = et_df.rename(columns={\"TimeStamp\": \"UnixTimeStamp\"})\n",
    "        et_df = et_df.reset_index(drop=True)\n",
    "        path = os.path.join(PROCESSED_DATA_PATH,df['ParticipantUuid'][i]+'_st_df'+'.csv')\n",
    "        print(100/df['ParticipantUuid'].count()*(i+1),\"%\")\n",
    "        et_df.to_csv(path)\n",
    "\n",
    "display(et_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de875445",
   "metadata": {},
   "source": [
    "### Combine Steering and ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34063596",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f'{PROCESSED_DATA_PATH}\\*.csv')\n",
    "for i in range(0,df['ParticipantUuid'].count()):\n",
    "    et_df = pd.DataFrame()\n",
    "    et_df2 = pd.DataFrame()\n",
    "    ne = pd.DataFrame()\n",
    "    for fi in files[:]: # reading all files\n",
    "        if df['ParticipantUuid'][i] in fi:\n",
    "            if et_df.empty:\n",
    "                et_df = pd.read_csv(fi)\n",
    "            else: \n",
    "                et_df2 = pd.read_csv(fi)\n",
    "                                \n",
    "                et_df2.set_index('timestamp', inplace=True)\n",
    "                et_df2 = et_df2.reset_index()\n",
    "                \n",
    "                #Check if DF are equally long\n",
    "                b = et_df2.shape[0]- et_df.shape[0]\n",
    "                et_df2.drop(et_df2.tail(b).index,inplace=True)\n",
    "                \n",
    "                et_df['Equal'] = np.where(et_df['timestamp'] == et_df2['timestamp'],'1','0')\n",
    "                et_df[['SteeringInput', 'AcellerationInput', 'BrakeInput']] = et_df2[['SteeringInput', 'AcellerationInput', 'BrakeInput']]\n",
    "                #print(ne)\n",
    "                path = os.path.join(COMBINED_DATA_PATH,df['ParticipantUuid'][i]+'_comb'+'.csv')\n",
    "                print(100/df['ParticipantUuid'].count()*(i+1),\"%\")\n",
    "                et_df.to_csv(path)\n",
    "\n",
    "                \n",
    "                        \n",
    "                #display(et_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb792f83",
   "metadata": {},
   "source": [
    "### Event Loading and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1755658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interims_df = pd.DataFrame()\n",
    "Event_dur_df = pd.DataFrame()\n",
    "\n",
    "files = glob.glob(f'{SCENE_EVENT_DATA_PATH}/*.txt')\n",
    "\n",
    "for i in range(0,df['ParticipantUuid'].count()):\n",
    "    event_samples_df = pd.DataFrame()\n",
    "    for fi in files[:]: # reading all files\n",
    "        if df['ParticipantUuid'][i] in fi:\n",
    "            with open(fi, 'r') as j:\n",
    "                tmp = json.loads(j.read())\n",
    "                x = tmp.get('EventBehavior')\n",
    "                for p in range(len(x)):\n",
    "                    tmpdf = pd.json_normalize(data=x[p], sep='_')\n",
    "                    interims_df = tmpdf[['EventName', 'StartofEventTimeStamp', 'EndOfEventTimeStamp',\n",
    "               'EventDuration', 'SuccessfulCompletionState', 'HitObjectName']]\n",
    "                    Event_dur_df = pd.concat([Event_dur_df,interims_df],ignore_index = True)\n",
    "                    tmpdf2 = pd.json_normalize(tmpdf[\"dynamicObjectData\"])\n",
    "                    for nS, sample in enumerate(tmpdf2):\n",
    "                        temp = list(tmpdf2[nS])\n",
    "                        tmpdf3 = pd.json_normalize(data=temp, sep='_')\n",
    "                        tmpdf3['uid'] = fi.split('\\\\')[-1].split('_')[0]\n",
    "                        tmpdf3['scene'] = fi.split('_')[-1].split('.')[0]\n",
    "                        tmpdf3[['EventName', 'StartofEventTimeStamp', 'EndOfEventTimeStamp',\n",
    "               'EventDuration', 'SuccessfulCompletionState', 'HitObjectName']] = interims_df[['EventName', 'StartofEventTimeStamp', 'EndOfEventTimeStamp',\n",
    "               'EventDuration', 'SuccessfulCompletionState', 'HitObjectName']]\n",
    "                        event_samples_df = pd.concat([event_samples_df, tmpdf3], ignore_index=True)\n",
    "    if not event_samples_df.empty:\n",
    "        event_samples_df = event_samples_df.drop_duplicates()\n",
    "        path = os.path.join(EVENT_DURATION_DATA_PATH,df['ParticipantUuid'][i]+'_event_dur'+'.csv')\n",
    "        event_samples_df['timestamp'] = pd.to_datetime(event_samples_df.UnixTimeStamp, utc=True, unit='s', origin='unix')\n",
    "        event_samples_df['StartofEventTime'] = pd.to_datetime(event_samples_df.StartofEventTimeStamp, utc=True, unit='s', origin='unix')\n",
    "        event_samples_df['EndofEventTime'] = pd.to_datetime(event_samples_df.EndOfEventTimeStamp, utc=True, unit='s', origin='unix')\n",
    "        event_samples_df = event_samples_df.sort_values(by=['timestamp'])\n",
    "        #event_samples_df = event_samples_df.reset_index(drop=True)\n",
    "        event_samples_df = event_samples_df.drop(['UnixTimeStamp', 'ObjectName0', 'ObjectName1', 'ObjectName2',\n",
    "       'ObjectPosition0.x', 'ObjectPosition0.y', 'ObjectPosition0.z','timestamp',\n",
    "       'ObjectRotation0.x', 'ObjectRotation0.y', 'ObjectRotation0.z',\n",
    "       'ObjectRotation0.w', 'ObjectPosition1.x', 'ObjectPosition1.y',\n",
    "       'ObjectPosition1.z', 'ObjectRotation1.x', 'ObjectRotation1.y',\n",
    "       'ObjectRotation1.z', 'ObjectRotation1.w', 'ObjectPosition2.x',\n",
    "       'ObjectPosition2.y', 'ObjectPosition2.z', 'ObjectRotation2.x',\n",
    "       'ObjectRotation2.y', 'ObjectRotation2.z', 'ObjectRotation2.w',  'StartofEventTimeStamp', 'EndOfEventTimeStamp',\n",
    "        'HitObjectName'\n",
    "       ],axis=1)\n",
    "        \n",
    "        event_samples_df = event_samples_df.drop_duplicates().reset_index(drop=True)\n",
    "        event_samples_df.to_csv(path)\n",
    "        \n",
    "        print(100/df['ParticipantUuid'].count()*(i+1),\"%\")\n",
    "        \n",
    "display(event_samples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad4105",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f'{EVENT_DURATION_DATA_PATH}\\*.csv')\n",
    "files_comb = glob.glob(f'{COMBINED_DATA_PATH}\\*.csv')\n",
    "#display(event_samples_df)\n",
    "et_dur_df = pd.DataFrame()\n",
    "for fi in files_comb[:]:\n",
    "    et_df = pd.read_csv(fi)\n",
    "    name = fi.split('\\\\')[-1].split('_')[0]\n",
    "    for fi2 in files[:]:\n",
    "        if name in fi2:\n",
    "            et_dur_df = pd.read_csv(fi2)\n",
    "            Start = et_df.iloc[0]['timestamp']\n",
    "            \n",
    "            #display(et_dur_df)\n",
    "            for t in range(0,12):\n",
    "                et_dur_df['StartofEventTime'][t]=(pd.to_datetime(et_dur_df['StartofEventTime'][t])-pd.to_datetime(Start)).total_seconds()\n",
    "                et_dur_df['EndofEventTime'][t]=(pd.to_datetime(et_dur_df['EndofEventTime'][t])-pd.to_datetime(Start)).total_seconds()\n",
    "            path = os.path.join(EVENT_DURATION_DATA_PATH,name+'_event_dur'+'.csv')\n",
    "            et_dur_df.to_csv(path)\n",
    "            #display(et_dur_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf935198",
   "metadata": {},
   "source": [
    "## Theta Calculations and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8181d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files_comb = glob.glob(f'{COMBINED_DATA_PATH}\\*.csv')\n",
    "et_samples_df = pd.DataFrame()\n",
    "for fi in files_comb[:]:\n",
    "    et_samples_df = pd.read_csv(fi)\n",
    "    \n",
    "    name = fi.split('\\\\')[-1].split('_')[0]\n",
    "    et_samples_df.reset_index(inplace=False)\n",
    "    et_samples_df['eye_theta_h'] = np.arctan2(et_samples_df['EyeDirectionCombinedLocal_x'], \n",
    "                                           et_samples_df['EyeDirectionCombinedLocal_z'])\n",
    "    et_samples_df['eye_theta_v'] = np.arctan2(et_samples_df['EyeDirectionCombinedLocal_y'], \n",
    "                                           et_samples_df['EyeDirectionCombinedLocal_z'])\n",
    "    et_samples_df['eye_theta_h_int'] = np.arctan2(et_samples_df['combinedEyeDir_x_intp'], \n",
    "                                           et_samples_df['combinedEyeDir_z_intp'])\n",
    "    et_samples_df['eye_theta_v_int'] = np.arctan2(et_samples_df['combinedEyeDir_y_intp'], \n",
    "                                           et_samples_df['combinedEyeDir_z_intp'])\n",
    "    path = os.path.join(COMBINED_DATA_PATH,name+'_comb'+'.csv')\n",
    "    et_samples_df.to_csv(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe3f88f",
   "metadata": {},
   "source": [
    "### Cut Data in Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556f14b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f'{EVENT_DURATION_DATA_PATH}\\*.csv')\n",
    "files_comb = glob.glob(f'{COMBINED_DATA_PATH}\\*.csv')\n",
    "for fi in files_comb[:1]:\n",
    "    et_df = pd.read_csv(fi)\n",
    "    name = fi.split('\\\\')[-1].split('_')[0]\n",
    "    print(name)\n",
    "    for fi2 in files[:]:\n",
    "        if name in fi2:\n",
    "            et_dur_df = pd.read_csv(fi2)\n",
    "            CutDatatoEvents(et_df,et_dur_df)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13141839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CutDatatoEvents(df,evt_df):\n",
    "    files = glob.glob(f'{ONLY_EVENTS_DATA_PATH}\\*.csv')\n",
    "    for index, row in evt_df.iterrows():\n",
    "        Event_O_df = pd.DataFrame()\n",
    "        EventStart = row['StartofEventTime']-1\n",
    "        EventEnd = row['EndofEventTime'] +1\n",
    "        Start_index = df['time_from_start'].sub(EventStart).abs().idxmin()\n",
    "        End_index = df['time_from_start'].sub(EventEnd).abs().idxmin()\n",
    "        EventName = row['EventName']\n",
    "        \n",
    "        path = os.path.join(ONLY_EVENTS_DATA_PATH,EventName+'.csv')\n",
    "\n",
    "        if \"..\\\\Only_Events\\\\\"+EventName+\".csv\" in files[:]:\n",
    "            Event_O_df = pd.read_csv(path)\n",
    "            #return \"nothing\"\n",
    "    #    menno = \" ICh war hier\"\n",
    "        else :\n",
    "            Event_O_df = pd.DataFrame()\n",
    "            #return \" something\"\n",
    "            #menno = \" oder auch nicht\"\n",
    "        new_df = df.loc[Start_index:End_index]\n",
    "        #Event_O_df = Event_O_df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "        Event_O_df = pd.concat([Event_O_df, new_df], ignore_index=True)\n",
    "        #path = os.path.join(ONLY_EVENTS_DATA_PATH,EventName+'.csv')\n",
    "        Event_O_df.to_csv(path)\n",
    "    return files\n",
    "\n",
    "    \n",
    "    \n",
    "    #get time frames for each event from evt_df\n",
    "    #search for corresponding indexes \n",
    "    #get 1 sec before and after event onset\n",
    "    #find timeinterval in df\n",
    "    #create new df for each event\n",
    "    #fill event df's with other participants events "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f62eee5",
   "metadata": {},
   "source": [
    "### Check Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865d7ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qualityCheck(df):\n",
    "    qualityList = []\n",
    "    #tobii timestamp count\n",
    "    o = df.query(\"TobiiTimeStamp==0\")\n",
    "    o = o.shape[0]\n",
    "    o = o/len(df.index)*100\n",
    "    #timestamp steering and ET\n",
    "    f = df.query(\"Equal==0\")\n",
    "    f = f.shape[0]\n",
    "    f = f/len(df.index)*100\n",
    "    #interpolated data over 1\n",
    "    g = df.query(\"combinedEyeDir_x_intp>1\")\n",
    "    g = g.shape[0]\n",
    "    g = g/len(df.index)*100\n",
    "    qualityList.append(o)\n",
    "    qualityList.append(f)\n",
    "    qualityList.append(g)\n",
    "    return qualityList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfd9b15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = glob.glob(f'{EVENT_DURATION_DATA_PATH}\\*.csv')\n",
    "files_comb = glob.glob(f'{COMBINED_DATA_PATH}\\*.csv')\n",
    "#display(event_samples_df)\n",
    "et_dur_df = pd.DataFrame()\n",
    "for fi in files_comb[:]:\n",
    "    et_df = pd.read_csv(fi)\n",
    "    name = fi.split('\\\\')[-1].split('_')[0]\n",
    "    for fi2 in files[:]:\n",
    "        if name in fi2:\n",
    "            et_dur_df = pd.read_csv(fi2)\n",
    "            xposition = et_dur_df['StartofEventTime']\n",
    "            x2position = et_dur_df['EndofEventTime']\n",
    "    ax = et_df.plot(kind=\"scatter\", x=\"time_from_start\",y= \"eye_theta_h\", color=\"b\", label=\"original\",figsize=(30,5),alpha = 0)\n",
    "    et_df.plot(kind=\"scatter\",x=\"time_from_start\",y=\"eye_theta_h_int\", color=\"r\", label=\"interpolated\", ax=ax, alpha=1)\n",
    "    et_df.plot(kind=\"scatter\",x=\"time_from_start\",y=\"SteeringInput\", color=\"y\", label=\"steering\", ax=ax, alpha=0.09)\n",
    "    et_df.plot(kind=\"scatter\",x=\"time_from_start\",y=\"Equal\", color=\"k\", label=\"timestamps equal\", ax=ax, alpha=0.01)\n",
    "    print(qualityCheck(et_df), \"%\")\n",
    "    \n",
    "    for xc in xposition:\n",
    "        ax.axvline(x=xc, color='g', linestyle='-',label = 'Event Start')\n",
    "    for xc2 in x2position:\n",
    "        ax.axvline(x=xc2, color='k', linestyle='-',label = 'Event End')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deda348f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = glob.glob(f'{ONLY_EVENTS_DATA_PATH}\\*.csv')\n",
    "for fi2 in files[:1]:\n",
    "    et_df = pd.read_csv(fi2)\n",
    "    #et_df.plot(\"time_from_start\")\n",
    "    ax = et_df.plot(kind=\"scatter\", x=\"time_from_start\",y= \"eye_theta_h\", color=\"b\", label=\"original\",alpha = 1)\n",
    "    et_df.plot(kind=\"scatter\",x=\"time_from_start\",y=\"eye_theta_h_int\", color=\"r\", label=\"interpolated\", ax=ax, alpha=1)\n",
    "    #et_df.plot(kind=\"scatter\",x=\"time_from_start\",y=\"SteeringInput\", color=\"y\", label=\"steering\", ax=ax, alpha=0.09)\n",
    "    #et_df.plot(kind=\"scatter\",x=\"time_from_start\",y=\"Equal\", color=\"k\", label=\"timestamps equal\", ax=ax, alpha=0.01)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44502b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
